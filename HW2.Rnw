\documentclass{article}
\usepackage{amsmath} %This allows me to use the align functionality.
                     %If you find yourself trying to replicate
                     %something you found online, ensure you're
                     %loading the necessary packages!
\usepackage{amsfonts}%Math font
\usepackage{graphicx}%For including graphics
\usepackage{hyperref}%For Hyperlinks
\hypersetup{colorlinks = true,citecolor=black}
\usepackage{natbib}        %For the bibliography
\bibliographystyle{apalike}%For the bibliography
\usepackage[margin=1.0in]{geometry}
\usepackage{float}
\begin{document}
\noindent \textbf{MA 354: Data Analysis -- Fall 2021 -- Due 10/8 at 5p}\\%\\ gives you a new line
\noindent \textbf{Homework 2:}\vspace{1em}\\
\emph{Complete the following opportunities to use what we've talked about in class. These questions will be graded for correctness, communication and succinctness. Ensure you show your work and explain your logic in a legible and refined submission.}
\begin{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%  Question 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item\label{Q1} Select a continuous distribution (Not the uniform or exponential). 
  It does not have to be one that we cover in the notes! To explore the PDF of your 
  distribution, specify two sets of parameter(s) for your distribution.
  \begin{enumerate}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (a)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item \textbf{History} Discuss what types of random variables are modeled with 
  your distribution. Be sure to include a discussion about the support and ensure 
  to provide the density function, and CDF. This requires some internet research 
  -- what's the history of the distribution, why was it created and named? What 
  are some exciting applications of this distribution?
  
  Cite all of your sources in LaTeX by adding a BibTeX citation to the .bib file. 
  To help, I've cited R \cite{R21} in parentheses here. \cite{R21} provides helpful 
  tools for the rest of the questions below. BibTeX citations are available through 
  Google Scholar by clicking the cite button below the article of  interest and 
  selecting the BibTeX option.\\
  \textbf{Solution:}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (b)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\item Show that you have a valid PDF. You will find the \texttt{integrate()} 
	function in \texttt{R} helpful.\\
  \textbf{Solution:}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (c)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\item Find the median for your two sets of parameter(s). Conduct some research 
	to find the median based on our PDF to confirm that your numerical approach is 
	correct.\\
  \textbf{Solution:}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (d)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\item \label{q1PDF} Graph the PDF for several values of the parameter(s) 
	including the two sets you specified. What does changing the parameter(s) do 
	to the shape of the PDF?\\
  \textbf{Solution:}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (e)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	 \item Graph the CDF for the same values of the parameter(s) as you did in 
	 Question \ref{q1PDF}. What does changing the parameter(s) do to the shape of 
	 the CDF? Comment on the aspects of the CDFs that show that the CDF is valid.\\
  \textbf{Solution:}
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (f)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Generate a random sample of size $n=10, 25, 100$, and $1000$ for your 
  two sets of parameter(s). In a $4 \times 2$ grid, plot a histogram of each set
  of data and superimpose the true density function at the specified parameter 
  values. Interpret the results.\\
  \textbf{Solution:}
	\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%  Question 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item Continue with the continuous distribution you selected for Question \ref{Q1}.
\begin{enumerate}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (a)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Provide the mean, standard deviation, skewness, and kurtosis of the PDF.
  Ensure to interpret each.\\
  \textbf{Solution:}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (b)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Generate a random sample of size $n=10, 25, 100$, and $1000$ for your 
  two sets of parameter(s). Calculate the sample mean, standard deviation, 
  skewness, and kurtosis. Interpret the results.\\
  \textbf{Solution:}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (c)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Generate a random sample of size $n=10$ for your two sets of parameter(s).
  Calculate the method of moments estimator(s) and maximum likelihood estimator(s).
  In a $1 \times 2$ grid, plot a histogram of each set of data with (1) the method 
  of moments estimated distribution, (2) the maximum likelihood estimated 
  distribution, and superimpose the true distribution in both.\\
  \textbf{Solution:}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (d)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Generate a random sample of size $n=25$ for your two sets of parameter(s).
  Calculate the method of moments estimator(s) and maximum likelihood estimator(s). 
  In a $1 \times 2$ grid, plot a histogram of each set of data with (1) the method 
  of moments estimated distribution, (2) the maximum likelihood estimated distribution, 
  and superimpose the true distribution in both.\\
  \textbf{Solution:}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (e)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Generate a random sample of size $n=100$ for your two sets of parameter(s). 
  Calculate the method of moments estimator(s) and maximum likelihood estimator(s).
  In a $1 \times 2$ grid, plot a histogram of each set of data with (1) the method 
  of moments estimated distribution, (2) the maximum likelihood estimated distribution,
  and superimpose the true distribution in both.\\
  \textbf{Solution:}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (f)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Generate a random sample of size $n=100$ for your two sets of parameter(s). 
  Calculate the method of moments estimator(s) and maximum likelihood estimator(s). 
  In a $1 \times 2$ grid, plot a histogram of each set of data with (1) the method 
  of moments estimated distribution, (2) the maximum likelihood estimated distribution, 
  and superimpose the true distribution in both.\\
  \textbf{Solution:}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (g)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Comment on the results of parts (c)-(f).\\
  \textbf{Solution:} 
\end{enumerate}
\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%  Question 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item\label{Q3} Select a discrete distribution (not the Poisson). It does not 
  have to be one that we cover in the notes! To explore the PMF of your distribution, 
  specify two sets of parameter(s) for your distribution.
  \begin{enumerate}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (a)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item \textbf{History} Discuss what types of random variables are modeled with 
  your distribution. Be sure to include a discussion about the support and ensure
  to provide the mass function, and CDF. This requires some internet research -- 
  what's the history of the distribution, why was it created and named? What are
  some exciting applications of this distribution? Cite all of your sources.\\
  
  \textbf{Solution:}
  The Bernoulli distribution, discussed in both \cite{chap6} and \cite{Bern}, is a special case of the binomial distribution, in which each observation can take one of two outcomes.  We define these as a ``success," where the observation of interest occurs, or a ``failure," where it does not.  Thus, the support for this distribution (or ``the set of all possible values of our random variable") is $\chi = \{x \in \{0,1\}\}$ (Cipolli, 163).  We use p to denote the probability that a ``success" occurs and $q=1-p$ to denote the probability that a ``failure" occurs. Thus, the probability mass function for the Bernoulli distribution is given by $f_X(x|p)=p^x(1-p)^{1-x}$, where x is either 0 or 1 (Sinharay, 132).  We can write this to be robust to other inputs by including an indicator function, I, such that the PMF is given by $f_X(x|p)=p^x(1-p)^{1-x}I(x\in\{0,1\})$ (Cipolli, 173). The cumulative distribution function of the Bernoulli distribution is given by:
$$ F_X(x|p) = 
\begin{cases} 
      0 & x < 0 \\
      1-p & 0\leq x <1 \\
      1 & 1\leq x 
   \end{cases}
$$
(Sinharay, 132).  We could similarly write this using floor operator as:
$$F_X(x|p) = [(1-p)I(\lfloor x \rfloor = 0)]+I(\lfloor x \rfloor \geq 1)
$$
(Cipolli, 173). The Bernoulli distribution is often used to in the context of flipping coins(Sinharay, 132).  A fair coin would be represented by a Bernoulli distribution with both $p$ and $q$ equal to 0.5 (while any other parameter values would represent an unfair coin flip).  I will investigate when the parameters p=0.5, q=0.5 and p=0.7,q=0.3.

  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (b)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\item Show that you have a valid PMF. You can show this approximately by 
	calculating the series in a repeat loop until probability mass evaluations are 
	infinitesimally small.\\
  
  \textbf{Solution:}
  For a PMF to be valid, all values of the PMF must remain within 0 and 1, and the sum of all PMF values over the support must be equal to one:
$$ 0\leq f_X(x)\leq 1 \hspace{.5cm} \text{for all } x \in \mathbb{R}$$
$$\sum_{-\infty}^{\infty} f_X(x)=\sum_{\chi} f_X(x)=1$$
(Cipolli, 167).  For a distribution like the Binomial distribution, for example, proving a PMF to be valid could require calculating it for increasing x until the probability is sufficiently small.  However, for the Bernoulli distribution, this is a little more direct because the support includes only two possible observations.  Thus, for each $p\in (0,1)$ for this distribution, the PMF will take only one of two forms:
$f_X(0|p)=p^0(1-p)^{1-0}=1-p$ or $f_X(1|p)=p^1(1-p)^{1-1}=p$.  Because $p\in (0,1)$, each of these possible values for the PMF will remain between 0 and 1, satisfying the first criteria.  Further, because $(1-p)+p=1$ the sum of these is always 1, satisfying the second criteria.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (c)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\item Find the median for your two sets of parameter(s). Conduct some research 
	to find the median based on our PMF to confirm that your numerical approach is
	correct.\\
  
  \textbf{Solution:}
  When p=0.5 and q=0.5, the median value depends in some ways on how we define some of the specifics of a median.  Because this situation represents a distribution where an equal number of ``successes" and ``failures" occur, we could say that there is no median.  We could also define the median as the in-between value $x=0.5$.
  When p=0.7 and q=0.3, the median value is more straightforward.  This distribution represents the case when 70\% of observations are ``successes" and 30\% are ``failures," and therefore the median value would be a ``success" with x=1.
  In general, the median would be equal to the x that maximizes the PMF.  The border case when $f_X(0|p)=f_X(1|p)$, as discussed above, depends on how we want to define the nuances of the median in our given context.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (d)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\item \label{q3PMF} Graph the PMF for several values of the parameter(s) 
	including the two sets you specified. What does changing the parameter(s) do 
	to the shape of the PMF?\\
	\textbf{Solution:}
	<<>>=
	##############################################################
	##    ADAPTED FROM CHAPTER 6 NOTES CODE: ch6-Bernoulli.R
	##############################################################
	
library("tidyverse")
library("ggplot2")
library("patchwork")
	
#############################################################
###Bernoulli Distribution ###################################
#############################################################
dbern<-function(x,prob){                #DEFINING THE PMF
  if(prob<0 | prob>1){
    errormsg <- "This function is only valid for success probabilities between 0 and 1."
    stop(errormsg)
  }
  indicator <- rep(0, length(x))
  indicator[x==0] <- 1 # indicator should be one if x=0
  indicator[x==1] <- 1 # indicator should be one if x=1
  fx <- (prob^x * (1-prob)^(1-x)) * indicator # PMF formula
  return(fx)
}

pbern<-function(q, prob){              
  if(prob<0 | prob>1){
    errormsg<-"This function is only valid for success probabilities between 0 and 1."
    stop(errormsg)
  }
  indicator1 <- rep(1, length(q))
  indicator1[q != 0] <- 0 #indicator should be zero if x!=0
  indicator2 <- rep(1, length(q))
  indicator2[q < 1] <- 0 #indicator should be zero if x<1
  Fx <- (1-prob) * indicator1 + indicator2
  return(Fx)
}
qbern <- function(p, prob){
  if(prob<0 | prob>1){
    errormsg<-"This function is only valid for success probabilities between 0 and 1."
    stop(errormsg)
  }
  if(any(p<0) | any(p>1)){
    errormsg<-"This function is only valid for percentiles between 0 and 1."
    stop(errormsg)
  }
  q <- rep(1, length(p))
  q[p <= 1-prob] <- 0 # should return zero if p<=(1-prob)
  q[p > 1-prob] <- 1  # should return one if p>(1-prob)
  return(q)
}

## Plots for the PMF
plotbern <- function(prob){ # Pass in the success probability
  ggdat <- data.frame(x = (-1:2),
                      f = dbern(x = (-1:2), prob = prob), #SETS X AXES NICELY
                      F = pbern(q = (-1:2), prob = prob))
  ## Plot PMF
  PMF <- ggplot(data = ggdat, aes(x = x)) +
    geom_linerange(aes(ymax = f), ymin = 0) +
    geom_hline(yintercept = 0) +
    theme_bw() +
    ylim(0, 1) +
    xlab("X") +
    ylab(bquote(f[x](x))) +
    ggtitle("Bernoulli PMF", subtitle = paste("p =", prob))

  return(PMF)
}
@
\begin{figure}
\centering
<<>>=
(plotbern(prob=0.25))/
  (plotbern(prob=0.50))/(plotbern(prob=0.75))
@
	\caption{Bernoulli Distribution PMFs for p=0.25, 0.5, and 0.75.}
	\label{BernPMF}
\end{figure}
	For all valid parameter values, the graph of the Bernoulli PMF shows two lines at the values 0 and 1, corresponding to the probabilities of those observations.  Thereby, the heights of these bars are controlled by the parameter p.  Lower parameter values correspond to a higher bar at X=0 and a lower bar at X=1, because the distribution represents a scenario in which it is more likely for a ``failure'' to occur (X=0) than a ``success" (X=1).  Higher parameter values correspond to a lower bar at X=0 and a higher bar at X=1, because the distribution represents a scenario in which it is more likely for a ``success'' to occur (X=1) than a ``failure" (X=0).  Three example PMFs of the Bernoulli distribution with varied parameter values are shown in figure \ref{BernPMF}.  I create these figures using \cite{ggplot}, \cite{tidyvers}, and \cite{patchwork}, and these are used throughout the homework to create plots.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (e)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	 \item Graph the CDF for the same values of the parameter(s) as you did in 
	 Question \ref{q3PMF}. What does changing the parameter(s) do to the shape of 
	 the CDF? Comment on the aspects of the CDFs that show that the CDF is valid.\\
	 \textbf{Solution:}
	 <<>>=
	##############################################################
	##    ADAPTED FROM CHAPTER 6 NOTES CODE: ch6-Bernoulli.R
	##############################################################

## Plots for the CDF
plotbern <- function(prob){ # Pass in the success probability
  ggdat <- data.frame(x = (-1:2),
                      f = dbern(x = (-1:2), prob = prob), #SETS X AXES NICELY
                      F = pbern(q = (-1:2), prob = prob))

  ggdat.openpoints <- data.frame(x = ggdat$x,
                                 y = pbern(ggdat$x-1, prob = prob))
  ggdat.closedpoints <- data.frame(x = ggdat$x,
                                   y = pbern(ggdat$x,prob=prob))
  CDF<-ggplot(data = ggdat, aes(x = x, y = F)) +
    geom_step()+
    geom_point(data = ggdat.openpoints, aes(x = x, y = y), shape = 1) +
    geom_point(data = ggdat.closedpoints, aes(x = x, y = y)) +
    theme_bw()+
    xlab("X")+
    ylab(bquote(F[x](x)))+
    ggtitle("Bernoulli CDF",subtitle=(paste("p =", prob)))
    return(CDF)
}
@
\begin{figure}
\centering
<<>>=
(plotbern(prob=0.25))/(plotbern(prob=0.50))/(plotbern(prob=0.75))
@
\caption{Bernoulli Distribution CDFs for p=0.25, 0.5, and 0.75.}
\label{BernCDF}
\end{figure}
  The changes in the CDF with varied parameter values are very similar to those of the PMF; because the CDF represents the cumulative sum of the PMF bars, before X=0, the CDF is 0.  The probability of observing an X lower than 0 is zero.  We can see that we have a valid CDF because at and after X=1, the CDF is 1. We are guaranteed to observe values only between 0 and 1 inclusive.  As with the PMF bars, lower parameter values correspond to a higher bar at X=0 (and therefore a lower bar at X=1 that takes the CDF to 1), because the distribution represents a scenario in which it is more likely for a ``failure'' to occur (X=0) than a ``success" (X=1).  Similarly again, higher parameter values correspond to a lower bar at X=0 (and therefore a higher bar at X=1 that takes the CDF to 1), because the distribution represents a scenario in which it is more likely for a ``success'' to occur (X=1) than a ``failure" (X=0).
  This results in a CDF that, visually, looks more ``concave up" for parameter values greater than 0.5, ``concave down" for values less than 0.5, and linear for values equal to 0.5.  Three example CDFs of the Bernoulli distribution with varied parameter values are shown in figure \ref{BernCDF}.
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (f)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Generate a random sample of size $n=10, 25, 100$, and $1000$ for your 
  two sets of parameter(s). In a $4 \times 2$ grid, plot a histogram (with bin 
  size 1) of each set of data and superimpose the true mass function at the 
  specified parameter values. Interpret the results.\\
  \textbf{Solution:}
<<>>=
##############################################################
	##    ADAPTED FROM CHAPTER 6 NOTES CODE (pg176)
	##############################################################

rbern<-function(n,p){
  support<-c(0,1)
  x<-sample(x=support, size=n, replace=TRUE, prob=dbern(support, p=p))
  return(x)
}

x.10.50   <-data.frame(rbern(10, .5))
x.25.50   <-data.frame(rbern(25, .5))
x.100.50  <-data.frame(rbern(100, .5))
x.1000.50 <-data.frame(rbern(1000, .5))

x.10.75   <-data.frame(rbern(10, .75))
x.25.75   <-data.frame(rbern(25, .75))
x.100.75  <-data.frame(rbern(100, .75))
x.1000.75 <-data.frame(rbern(1000, .75))
## PMF for p=0.5 
ggdat <- data.frame(x = (-1:2),
                      f = dbern(x = (-1:2), prob = 0.5),
                      F = pbern(q = (-1:2), prob = 0.5))

g1<-ggplot(NULL) +                                      #left NULL so that we can superimpose
  geom_histogram(data=x.10.50,                          #uses random sample
                 aes(x=rbern.10..0.5.),                 #makes histogram
                 breaks=seq(-0.5,1.5,1),                #Set up bins to use
                 fill = "lightgrey", color="black") +   #color the histogram
  xlab("X") +                                           #x axis label
  ylab("Frequency")+                                    #y axis label
  ggtitle("Random Bernoulli Distribution", 
          subtitle = "With p=0.5 and n=10") +           #add title to plot
  geom_hline(yintercept=0) +                            #adds a line for the x-axis
  geom_linerange(data=ggdat,                            #uses earlier PMF data
                 aes(x=x, ymax=10*f, ymin=0),           #Adds PMF (weighted by number of observations)
                 color="red")                           #Makes PMF red

g2<-ggplot(NULL) +                                      #left NULL so that we can superimpose
  geom_histogram(data=x.25.50,                          #uses random sample
                 aes(x=rbern.25..0.5.),                 #makes histogram
                 breaks=seq(-0.5,1.5,1),                #Set up bins to use
                 fill = "lightgrey", color="black") +   #color the histogram
  xlab("X") +                                           #x axis label
  ylab("Frequency")+                                    #y axis label
  ggtitle("Random Bernoulli Distribution", 
          subtitle = "With p=0.5 and n=25") +           #add title to plot
  geom_hline(yintercept=0) +                            #adds a line for the x-axis
  geom_linerange(data=ggdat,                            #uses earlier PMF data
                 aes(x=x, ymax=25*f, ymin=0),           #Adds PMF (weighted by number of observations)
                 color="red")                           #Makes PMF red
  
g3<-ggplot(NULL) +                                      #left NULL so that we can superimpose
  geom_histogram(data=x.100.50,                         #uses random sample
                 aes(x=rbern.100..0.5.),                #makes histogram
                 breaks=seq(-0.5,1.5,1),                #Set up bins to use
                 fill = "lightgrey", color="black") +   #color the histogram
  xlab("X") +                                           #x axis label
  ylab("Frequency")+                                    #y axis label
  ggtitle("Random Bernoulli Distribution", 
          subtitle = "With p=0.5 and n=100") +          #add title to plot
  geom_hline(yintercept=0) +                            #adds a line for the x-axis
  geom_linerange(data=ggdat,                            #uses earlier PMF data
                 aes(x=x, ymax=100*f, ymin=0),          #Adds PMF (weighted by number of observations)
                 color="red")                           #Makes PMF red
  
  
g4<-ggplot(NULL) +                                      #left NULL so that we can superimpose
  geom_histogram(data=x.1000.50,                        #uses random sample
                 aes(x=rbern.1000..0.5.),               #makes histogram
                 breaks=seq(-0.5,1.5,1),                #Set up bins to use
                 fill = "lightgrey", color="black") +   #color the histogram
  xlab("X") +                                           #x axis label
  ylab("Frequency")+                                    #y axis label
  ggtitle("Random Bernoulli Distribution", 
          subtitle = "With p=0.5 and n=1000") +         #add title to plot
  geom_hline(yintercept=0) +                            #adds a line for the x-axis
  geom_linerange(data=ggdat,                            #uses earlier PMF data
                 aes(x=x, ymax=1000*f, ymin=0),         #Adds PMF (weighted by number of observations)
                 color="red")                           #Makes PMF red

## PMF for p=0.5 
ggdat <- data.frame(x = (-1:2),
                      f = dbern(x = (-1:2), prob = 0.75),
                      F = pbern(q = (-1:2), prob = 0.75))

g5<-ggplot(NULL) +                                      #left NULL so that we can superimpose
  geom_histogram(data=x.10.75,                          #uses random sample
                 aes(x=rbern.10..0.75.),                #makes histogram
                 breaks=seq(-0.5,1.5,1),                #Set up bins to use
                 fill = "lightgrey", color="black") +   #color the histogram
  xlab("X") +                                           #x axis label
  ylab("Frequency")+                                    #y axis label
  ggtitle("Random Bernoulli Distribution", 
          subtitle = "With p=0.75 and n=10") +          #add title to plot
  geom_hline(yintercept=0) +                            #adds a line for the x-axis
  geom_linerange(data=ggdat,                            #uses earlier PMF data
                 aes(x=x, ymax=10*f, ymin=0),           #Adds PMF (weighted by number of observations)
                 color="red")                           #Makes PMF red

g6<-ggplot(NULL) +                                      #left NULL so that we can superimpose
  geom_histogram(data=x.25.75,                          #uses random sample
                 aes(x=rbern.25..0.75.),                #makes histogram
                 breaks=seq(-0.5,1.5,1),                #Set up bins to use
                 fill = "lightgrey", color="black") +   #color the histogram
  xlab("X") +                                           #x axis label
  ylab("Frequency")+                                    #y axis label
  ggtitle("Random Bernoulli Distribution", 
          subtitle = "With p=0.75 and n=25") +          #add title to plot
  geom_hline(yintercept=0) +                            #adds a line for the x-axis
  geom_linerange(data=ggdat,                            #uses earlier PMF data
                 aes(x=x, ymax=25*f, ymin=0),           #Adds PMF (weighted by number of observations)
                 color="red")                           #Makes PMF red
  
g7<-ggplot(NULL) +                                      #left NULL so that we can superimpose
  geom_histogram(data=x.100.75,                         #uses random sample
                 aes(x=rbern.100..0.75.),               #makes histogram
                 breaks=seq(-0.5,1.5,1),                #Set up bins to use
                 fill = "lightgrey", color="black") +   #color the histogram
  xlab("X") +                                           #x axis label
  ylab("Frequency")+                                    #y axis label
  ggtitle("Random Bernoulli Distribution", 
          subtitle = "With p=0.75 and n=100") +         #add title to plot
  geom_hline(yintercept=0) +                            #adds a line for the x-axis
  geom_linerange(data=ggdat,                            #uses earlier PMF data
                 aes(x=x, ymax=100*f, ymin=0),          #Adds PMF (weighted by number of observations)
                 color="red")                           #Makes PMF red
  
  
g8<-ggplot(NULL) +                                      #left NULL so that we can superimpose
  geom_histogram(data=x.1000.75,                        #uses random sample
                 aes(x=rbern.1000..0.75.),               #makes histogram
                 breaks=seq(-0.5,1.5,1),                #Set up bins to use
                 fill = "lightgrey", color="black") +   #color the histogram
  xlab("X") +                                           #x axis label
  ylab("Frequency")+                                    #y axis label
  ggtitle("Random Bernoulli Distribution", 
          subtitle = "With p=0.75 and n=1000") +        #add title to plot
  geom_hline(yintercept=0) +                            #adds a line for the x-axis
  geom_linerange(data=ggdat,                            #uses earlier PMF data
                 aes(x=x, ymax=1000*f, ymin=0),         #Adds PMF (weighted by number of observations)
                 color="red")                           #Makes PMF red
@
\begin{figure}[H]
\centering
<<>>=
(g1 + g5) / (g2 + g6) / (g3 + g7) / (g4 + g8)
@
\caption{Bernoulli Distributionsfor randomly generated samples, with varied n and p.  The red lines prepresent the PMF, while the histograms show the observed counts.}
\label{BernRand}
\end{figure}
  The greater the size of our random samples, the closer, generally, the spread of the observations we make are to the number we would predict from the PMF.  We can see this in that the heights of the grey histogram bars seem to get closer to the red lines that represent the PMF's prediction.
	\end{enumerate}
	\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%  Question 4 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item Continue with the discrete distribution you selected for Question \ref{Q3}.
\begin{enumerate}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (a)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Provide the mean, standard deviation, skewness, and kurtosis of the PMF. 
  Ensure to interpret each.\\
  \textbf{Solution:}
  <<>>=
bern.summ <- function(p){
  bern.mean <- p                     #mean = expected value = p
  bern.sd   <- sqrt(p*(1-p))         #sqrt of variance
  bern.skew <- (1-2*p)/bern.sd        
  bern.kurt <- (1-6*p*(1-p))/(p*(1-p))
  return(c(bern.mean,bern.sd,bern.skew,bern.kurt))
}

bern.summ(0.5)
bern.summ(0.75)
@
For the parameter 0.5, both the mean and standard deviation are 0.5.  This makes 
sense, as with this probability, there are an equal number of observations of 0 
and 1, making the mean 0.5 and standard deviation 0.5 (as both 0 and 1 are 0.5 away 
from the mean 0.5).  Because it is a symmetric distribution, the skewness is zero.
The kurtosis is -2, representing this flat, platykurtic distribution.

For the parameter 0.75, both the mean is 0.75 and with standard deviation 0.433.
Because it is not symmetric distribution, with higher values occuring more frequently,
the skewness is -1.15. The kurtosis is -0.67, again representing a platykurtic distribution.

  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (b)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Generate a random sample of size $n=10, 25, 100$, and $1000$ for your 
  two sets of parameter(s). Calculate the sample mean, standard deviation, 
  skewness, and kurtosis. Interpret the results.\\
  \textbf{Solution:}
    <<>>=
library(e1071)
## n=10, p=0.5
x.10.50   <-rbern(10, .5)
c(mean(x.10.50),
  sd(x.10.50),
  skewness(x.10.50),
  kurtosis(x.10.50))

## n=25, p=0.5
x.25.50   <-rbern(25, .5)
c(mean(x.25.50),
  sd(x.25.50),
  skewness(x.25.50),
  kurtosis(x.25.50))

## n=100, p=0.5
x.100.50  <-rbern(100, .5)
c(mean(x.100.50),
  sd(x.100.50),
  skewness(x.100.50),
  kurtosis(x.100.50))

## n=1000, p=0.5
x.1000.50 <-rbern(1000, .5)
c(mean(x.1000.50),
  sd(x.1000.50),
  skewness(x.1000.50),
  kurtosis(x.1000.50))

## n=10, p=0.75
x.10.75   <-rbern(10, .75)
c(mean(x.10.75),
  sd(x.10.50),
  skewness(x.10.75),
  kurtosis(x.10.75))

## n=25, p=0.75
x.25.75   <-rbern(25, .75)
c(mean(x.25.75),
  sd(x.25.50),
  skewness(x.25.75),
  kurtosis(x.25.75))

## n=100, p=0.75
x.100.75  <-rbern(100, .75)
c(mean(x.100.75),
  sd(x.100.75),
  skewness(x.100.75),
  kurtosis(x.100.75))

## n=1000, p=0.75
x.1000.75 <-rbern(1000, .75)
c(mean(x.1000.75),
  sd(x.1000.75),
  skewness(x.1000.75),
  kurtosis(x.1000.75))
@
The values seen here are close to the ones predicted above.  We can see that in the cases that p=0.5,
the mean, standard deviation, skewness, and kurtosis remain relatively close to the predicted
0.5, 0.5, 0, and -2, respectively.  Similarly, in the cases that p=0.75, the mean, standard deviation, skewness, and 
kurtosis remain relatively close to the predicted 0.75, 0.433, -1.15, and -0.67.
Further, it seems that generally, as n increases, the summary statistics derived from observation approach
those predicted.  The package e1071, from \cite{e1071}, is used for the calculation of skewness and kurtosis.
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (c)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Generate a random sample of size $n=10$ for your two sets of parameter(s).
  Calculate the method of moments estimator(s) and maximum likelihood estimator(s).
  In a $1 \times 2$ grid, plot a histogram (with bin size 1) of each set of data 
  with (1) the method of moments estimated distribution, (2) the maximum likelihood 
  estimated distribution, and superimpose the true distribution in both.\\
  \textbf{Solution:}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (d)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Generate a random sample of size $n=25$ for your two sets of parameter(s). 
  Calculate the method of moments estimator(s) and maximum likelihood estimator(s).
  In a $1 \times 2$ grid, plot a histogram (with bin size 1) of each set of data 
  with (1) the method of moments estimated distribution, (2) the maximum likelihood 
  estimated distribution, and superimpose the true distribution in both.\\
  \textbf{Solution:}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (e)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Generate a random sample of size $n=100$ for your two sets of parameter(s).
  Calculate the method of moments estimator(s) and maximum likelihood estimator(s). 
  In a $1 \times 2$ grid, plot a histogram (with bin size 1) of each set of data 
  with (1) the method of moments estimated distribution, (2) the maximum likelihood
  estimated distribution, and superimpose the true distribution in both.\\
  \textbf{Solution:}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (f)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Generate a random sample of size $n=1000$ for your two sets of parameter(s).
  Calculate the method of moments estimator(s) and maximum likelihood estimator(s).
  In a $1 \times 2$ grid, plot a histogram (with bin size 1) of each set of data 
  with (1) the method of moments estimated distribution, (2) the maximum likelihood
  estimated distribution, and superimpose the true distribution in both.\\
  \textbf{Solution:}
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %%%%%%%%%  Part (g)
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Comment on the results of parts (c)-(f).\\
  \textbf{Solution:}
  
\end{enumerate}
\end{enumerate}%End overall enumerate
\newpage
\bibliography{bib}
\end{document}
